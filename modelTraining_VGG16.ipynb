{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgPaxKukr4zP"
   },
   "source": [
    "# **VGG16 Model with 31 classes = 3100 pics of dataset of sneaker (Sneaker Recognition ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s15o_7Qaduqb"
   },
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow\n",
    "!pip uninstall keras\n",
    "!pip install tensorflow==1.13.0rc1\n",
    "!pip install keras==2.1.3\n",
    "#reinstall version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_Q_9MGgv8WQ"
   },
   "source": [
    "# import lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtgCrOYur4zS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential,Model,load_model,model_from_json\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten,Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJ3u0FohwFmu"
   },
   "source": [
    "# open folder from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "X5qksAT5sH_K",
    "outputId": "f6615a21-fbca-4693-fafd-351269ddc7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vd86cYdgwQsw"
   },
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z6ytO8i0r4zY",
    "outputId": "f3fb3586-dcd3-4513-88be-0171ef412935",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2790 images belonging to 31 classes.\n",
      "Found 311 images belonging to 31 classes.\n"
     ]
    }
   ],
   "source": [
    "#generate data form image\n",
    "#preprocessing image by rescale form 0-255 to 0-1 for easy to use in CNN\n",
    "path_clean = '/content/gdrive/My Drive/Project 62 - preaw+playfa/Clean'\n",
    "path_test = '/content/gdrive/My Drive/Project 62 - preaw+playfa/test/test'\n",
    "train_datagen = ImageDataGenerator(\n",
    "                           rescale=1.0/255.0,\n",
    "                           horizontal_flip=True,\n",
    "                           shear_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           width_shift_range=0.1,\n",
    "                           height_shift_range=0.1,\n",
    "                           fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                           rescale=1.0/255.0,\n",
    "                           horizontal_flip=True,\n",
    "                           shear_range=0.2,\n",
    "                           zoom_range=0.2,\n",
    "                           width_shift_range=0.1,\n",
    "                           height_shift_range=0.1,\n",
    "                           fill_mode='nearest')\n",
    "\n",
    "#ceil(dataset_size / batch_size)\n",
    "batch_size=32\n",
    "train_steps = ceil(2790/batch_size)\n",
    "validation_steps = ceil(311/batch_size)\n",
    "\n",
    "\n",
    "traindata = train_datagen.flow_from_directory(path_clean, target_size = (224, 224), batch_size = batch_size, class_mode='categorical')\n",
    "validationdata = test_datagen.flow_from_directory(path_test, target_size = (224, 224), batch_size = batch_size, class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpLXIRcWwZoZ"
   },
   "source": [
    "# load pre-trained model vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "aBmVkYBdr4zc",
    "outputId": "954428c3-c461-4652-a801-7ba48f4034c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "compiling\n",
      "model compiled\n"
     ]
    }
   ],
   "source": [
    "def pretrain_classifier_top ():\n",
    "    model_vgg16 = VGG16(weights='imagenet', include_top=False)  ### no top layers , imagenet weights\n",
    "    \n",
    "    #freeze all layers\n",
    "    for layer in model_vgg16.layers:\n",
    "      layer.trainable = False\n",
    "      \n",
    "    #Set input format\n",
    "    keras_input = Input(shape=(224,224,3), name = 'image_input')\n",
    "    \n",
    "    #new vgg16 model \n",
    "    output_vgg16_conv = model_vgg16(keras_input)\n",
    "    \n",
    "    #New classifier layers\n",
    "    new = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    new = Dense(4096, activation='relu', name='fc1')(new)\n",
    "    new = Dense(4096, activation='relu', name='fc2')(new)\n",
    "    new = Dense(31, activation='softmax', name='predictions')(new)\n",
    "    print(\"compiling\")\n",
    "    pretrained_model = Model(inputs=keras_input, outputs=new)\n",
    "    #pretrained_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    pretrained_model.compile(loss='categorical_crossentropy',  optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.8), metrics=['accuracy'])\n",
    "    print(\"model compiled\")\n",
    "    \n",
    "    return pretrained_model\n",
    "model2 = pretrain_classifier_top() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5dcuwSlwkyE"
   },
   "source": [
    "# train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "opGYGiGkr4zh",
    "outputId": "154ed198-90b0-4b68-f8d0-518f87e3de4c"
   },
   "outputs": [],
   "source": [
    "showmodel = model2.fit_generator(traindata,\n",
    "                                   steps_per_epoch=train_steps,\n",
    "                                   epochs=20,\n",
    "                                  validation_data=validationdata,\n",
    "                                   validation_steps=validation_steps)\n",
    "print(\"----------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wy-qH4gnwsz-"
   },
   "source": [
    "# show accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "L5lg98XQr4zl",
    "outputId": "0fd61c8f-9b88-4092-94a0-fcf3d2e8e2fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuracy: 0.8831541219065266 0.6810183269148659\n",
      "\n",
      "Test accuracy: 0.8392282952449712 0.7733322153904048\n"
     ]
    }
   ],
   "source": [
    "#eveluate Model\n",
    "train_loss, train_acc = model2.evaluate_generator(generator=traindata,steps=train_steps)\n",
    "print('\\nTrain accuracy:', train_acc,train_loss)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model2.evaluate_generator(generator=validationdata,steps=validation_steps)\n",
    "print('\\nTest accuracy:', test_acc,test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKnY1RKJr4zq"
   },
   "outputs": [],
   "source": [
    "#json_file = open('model_architectureReal.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#loaded_model.load_weights(\"modelReal.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6EAqTZDw16I"
   },
   "source": [
    "# prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "UAcDzUKor4zu",
    "outputId": "3f8ab6b5-a539-4639-d62c-80ccef14012e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 311 images belonging to 31 classes.\n",
      "10/10 [==============================] - 290s 29s/step\n"
     ]
    }
   ],
   "source": [
    "#create class \n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "testdata = test_datagen.flow_from_directory(path_test, target_size = (224, 224),batch_size=32,shuffle=False)\n",
    "test_steps_per_epoch = ceil(testdata.samples / testdata.batch_size)\n",
    "\n",
    "predict = model2.predict_generator(testdata,steps=test_steps_per_epoch,verbose=1)\n",
    "predicted_class=np.argmax(predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N7BJLcHjr4zy",
    "outputId": "911233bf-7e8e-4838-8d23-3a165811cd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0   0\n",
      "1 0   0\n",
      "2 0   0\n",
      "3 0   0\n",
      "4 0   0\n",
      "5 0   0\n",
      "6 0   0\n",
      "7 0   0\n",
      "8 0   0\n",
      "9 0   0\n",
      "10 1   1\n",
      "11 1   1\n",
      "12 1   1\n",
      "13 1   1\n",
      "14 1   6\n",
      "15 1   1\n",
      "16 1   1\n",
      "17 1   1\n",
      "18 1   1\n",
      "19 1   1\n",
      "20 2   2\n",
      "21 2   2\n",
      "22 2   2\n",
      "23 2   2\n",
      "24 2   2\n",
      "25 2   2\n",
      "26 2   13\n",
      "27 2   2\n",
      "28 2   2\n",
      "29 2   2\n",
      "30 3   3\n",
      "31 3   2\n",
      "32 3   3\n",
      "33 3   3\n",
      "34 3   16\n",
      "35 3   3\n",
      "36 3   7\n",
      "37 3   3\n",
      "38 3   3\n",
      "39 3   3\n",
      "40 4   4\n",
      "41 4   4\n",
      "42 4   24\n",
      "43 4   7\n",
      "44 4   4\n",
      "45 4   3\n",
      "46 4   4\n",
      "47 4   29\n",
      "48 4   4\n",
      "49 4   22\n",
      "50 5   5\n",
      "51 5   7\n",
      "52 5   5\n",
      "53 5   5\n",
      "54 5   5\n",
      "55 5   5\n",
      "56 5   5\n",
      "57 5   5\n",
      "58 5   5\n",
      "59 5   5\n",
      "60 6   6\n",
      "61 6   6\n",
      "62 6   6\n",
      "63 6   6\n",
      "64 6   6\n",
      "65 6   6\n",
      "66 6   6\n",
      "67 6   6\n",
      "68 6   6\n",
      "69 6   10\n",
      "70 7   7\n",
      "71 7   7\n",
      "72 7   7\n",
      "73 7   7\n",
      "74 7   7\n",
      "75 7   7\n",
      "76 7   7\n",
      "77 7   7\n",
      "78 7   7\n",
      "79 7   7\n",
      "80 8   8\n",
      "81 8   8\n",
      "82 8   8\n",
      "83 8   8\n",
      "84 8   8\n",
      "85 8   8\n",
      "86 8   8\n",
      "87 8   8\n",
      "88 8   8\n",
      "89 8   8\n",
      "90 9   9\n",
      "91 9   9\n",
      "92 9   9\n",
      "93 9   9\n",
      "94 9   9\n",
      "95 9   9\n",
      "96 9   9\n",
      "97 9   9\n",
      "98 9   9\n",
      "99 9   9\n",
      "100 10   10\n",
      "101 10   10\n",
      "102 10   10\n",
      "103 10   10\n",
      "104 10   10\n",
      "105 10   10\n",
      "106 10   10\n",
      "107 10   10\n",
      "108 10   10\n",
      "109 10   10\n",
      "110 11   11\n",
      "111 11   11\n",
      "112 11   11\n",
      "113 11   11\n",
      "114 11   11\n",
      "115 11   11\n",
      "116 11   11\n",
      "117 11   11\n",
      "118 11   11\n",
      "119 11   11\n",
      "120 12   12\n",
      "121 12   12\n",
      "122 12   12\n",
      "123 12   12\n",
      "124 12   12\n",
      "125 12   12\n",
      "126 12   12\n",
      "127 12   12\n",
      "128 12   12\n",
      "129 12   12\n",
      "130 13   13\n",
      "131 13   13\n",
      "132 13   13\n",
      "133 13   13\n",
      "134 13   13\n",
      "135 13   13\n",
      "136 13   13\n",
      "137 13   13\n",
      "138 13   13\n",
      "139 13   13\n",
      "140 14   14\n",
      "141 14   14\n",
      "142 14   14\n",
      "143 14   14\n",
      "144 14   14\n",
      "145 14   14\n",
      "146 14   12\n",
      "147 14   14\n",
      "148 14   14\n",
      "149 14   14\n",
      "150 15   15\n",
      "151 15   15\n",
      "152 15   15\n",
      "153 15   17\n",
      "154 15   7\n",
      "155 15   15\n",
      "156 15   15\n",
      "157 15   15\n",
      "158 15   15\n",
      "159 15   15\n",
      "160 16   16\n",
      "161 16   16\n",
      "162 16   10\n",
      "163 16   16\n",
      "164 16   16\n",
      "165 16   16\n",
      "166 16   16\n",
      "167 16   16\n",
      "168 16   16\n",
      "169 16   16\n",
      "170 17   17\n",
      "171 17   17\n",
      "172 17   17\n",
      "173 17   17\n",
      "174 17   17\n",
      "175 17   18\n",
      "176 17   5\n",
      "177 17   17\n",
      "178 17   17\n",
      "179 17   17\n",
      "180 18   18\n",
      "181 18   18\n",
      "182 18   18\n",
      "183 18   18\n",
      "184 18   18\n",
      "185 18   18\n",
      "186 18   7\n",
      "187 18   18\n",
      "188 18   18\n",
      "189 18   18\n",
      "190 19   19\n",
      "191 19   19\n",
      "192 19   19\n",
      "193 19   19\n",
      "194 19   19\n",
      "195 19   19\n",
      "196 19   19\n",
      "197 19   19\n",
      "198 19   19\n",
      "199 19   19\n",
      "200 20   20\n",
      "201 20   20\n",
      "202 20   3\n",
      "203 20   20\n",
      "204 20   20\n",
      "205 20   20\n",
      "206 20   20\n",
      "207 20   3\n",
      "208 20   20\n",
      "209 20   20\n",
      "210 21   27\n",
      "211 21   21\n",
      "212 21   21\n",
      "213 21   4\n",
      "214 21   3\n",
      "215 21   21\n",
      "216 21   10\n",
      "217 21   21\n",
      "218 21   24\n",
      "219 21   21\n",
      "220 22   22\n",
      "221 22   22\n",
      "222 22   22\n",
      "223 22   19\n",
      "224 22   22\n",
      "225 22   22\n",
      "226 22   22\n",
      "227 22   22\n",
      "228 22   22\n",
      "229 22   22\n",
      "230 23   23\n",
      "231 23   23\n",
      "232 23   23\n",
      "233 23   23\n",
      "234 23   23\n",
      "235 23   23\n",
      "236 23   23\n",
      "237 23   23\n",
      "238 23   23\n",
      "239 23   23\n",
      "240 24   24\n",
      "241 24   24\n",
      "242 24   24\n",
      "243 24   24\n",
      "244 24   24\n",
      "245 24   3\n",
      "246 24   10\n",
      "247 24   24\n",
      "248 24   24\n",
      "249 24   24\n",
      "250 25   29\n",
      "251 25   25\n",
      "252 25   25\n",
      "253 25   25\n",
      "254 25   25\n",
      "255 25   25\n",
      "256 25   25\n",
      "257 25   25\n",
      "258 25   25\n",
      "259 25   25\n",
      "260 26   26\n",
      "261 26   26\n",
      "262 26   26\n",
      "263 26   26\n",
      "264 26   26\n",
      "265 26   26\n",
      "266 26   26\n",
      "267 26   26\n",
      "268 26   26\n",
      "269 26   26\n",
      "270 26   26\n",
      "271 27   27\n",
      "272 27   27\n",
      "273 27   27\n",
      "274 27   27\n",
      "275 27   28\n",
      "276 27   27\n",
      "277 27   27\n",
      "278 27   27\n",
      "279 27   27\n",
      "280 27   27\n",
      "281 28   28\n",
      "282 28   28\n",
      "283 28   28\n",
      "284 28   28\n",
      "285 28   28\n",
      "286 28   28\n",
      "287 28   28\n",
      "288 28   28\n",
      "289 28   28\n",
      "290 28   28\n",
      "291 29   29\n",
      "292 29   29\n",
      "293 29   29\n",
      "294 29   29\n",
      "295 29   29\n",
      "296 29   29\n",
      "297 29   29\n",
      "298 29   29\n",
      "299 29   29\n",
      "300 29   29\n",
      "301 30   30\n",
      "302 30   11\n",
      "303 30   30\n",
      "304 30   30\n",
      "305 30   30\n",
      "306 30   23\n",
      "307 30   30\n",
      "308 30   30\n",
      "309 30   30\n",
      "310 30   25\n"
     ]
    }
   ],
   "source": [
    "#predict data form 100 image test set\n",
    "true_class = testdata.classes\n",
    "class_labels = list(testdata.class_indices.keys())\n",
    "\n",
    "report = metrics.classification_report(true_class, predicted_class, target_names=class_labels)\n",
    "#print(report)    \n",
    "\n",
    "#print(true_class)\n",
    "for i in range (0,311):\n",
    "  print(i,true_class[i],' ',predicted_class[i])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aS9JwZS1xClz"
   },
   "source": [
    "# save model , weight and prediction into .h5 , .json , .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JriThvO4r4z1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save model & weight & result from 100 testing data into .csv file\n",
    "#filenames=testdata.filenames\n",
    "filenames=true_class\n",
    "print (\"\",len(filenames))\n",
    "print (\"\",len(predicted_class))\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                     \"Predictions\":predicted_class})\n",
    "results.to_csv('Result_16042020.csv',index=False)\n",
    "with open('Result_16042020.json', 'w') as f:\n",
    "    f.write(model2.to_json())\n",
    "model2.save_weights('Result_16042020_1.h5')\n",
    "\n",
    "from google.colab import files\n",
    "#files.download('Final31classesResult.csv')\n",
    "model2.save('Result_16042020_2.h5') \n",
    "files.download('Result_16042020_1.h5')\n",
    "files.download('Result_16042020_2.h5')\n",
    "files.download('Result_16042020.json')\n",
    "files.download('Result_16042020t.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdOgE4o1xVDE"
   },
   "source": [
    "# show graph plot from train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHmgJUhcr4z7"
   },
   "outputs": [],
   "source": [
    "#กราฟแสดงค่าaccuracy\n",
    "plt.plot(showmodel.history['acc'])\n",
    "plt.plot(showmodel.history['val_acc'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "#กราฟแสดงค่าloss\n",
    "plt.plot(showmodel.history['loss'])\n",
    "plt.plot(showmodel.history['val_loss'])\n",
    "plt.title('model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LSIuW0Fr4z_"
   },
   "outputs": [],
   "source": [
    "print(model2.summary()) # show model summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "modelTraining_VGG16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
